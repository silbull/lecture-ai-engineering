{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f148279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95c4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/bin/python\n",
      "uv not found\n",
      "Python 3.12.10\n"
     ]
    }
   ],
   "source": [
    "!pip list\n",
    "!which python\n",
    "!which uv\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfe80c",
   "metadata": {},
   "source": [
    "ngrok と huggigface のトークンを使用して、認証を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840a4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /home/tmiya/.config/ngrok/ngrok.yml\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `ai-enginnering-token` has been saved to /home/tmiya/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/tmiya/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `ai-enginnering-token`\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken $$NGROK_TOKEN\n",
    "!huggingface-cli login --token $$HUGGINGFACE_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397885f9",
   "metadata": {},
   "source": [
    "stramlit で Huggingface のトークン情報を扱うために、streamlit 用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .streamlit/secrets.toml ファイルを作成\n",
    "import os\n",
    "\n",
    "import toml\n",
    "\n",
    "# 設定ファイルのディレクトリ確保\n",
    "os.makedirs(\".streamlit\", exist_ok=True)\n",
    "\n",
    "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
    "secrets = {\"huggingface\": {\"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")}}\n",
    "\n",
    "# 設定ファイルを書き込む\n",
    "with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
    "    toml.dump(secrets, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17256fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 16.51it/s]\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ モデルロード成功！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from config import MODEL_NAME\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_NAME,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=device,\n",
    ")\n",
    "print(\"✅ モデルロード成功！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444e2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ワンピースって知っている？？\n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ワンピースって知っている？？\"\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=200,  # 出力の最大トークン数（文章の長さ）\n",
    "    temperature=0.7,  # ランダム性（小さいほど堅い、1.0なら自由）\n",
    "    top_p=0.95,  # nucleus sampling（通常これで十分）\n",
    "    do_sample=True,  # サンプリングするか（True推奨）\n",
    ")\n",
    "\n",
    "# 結果表示\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1f9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://172.22.108.179:8501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:8501: Operation not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 公開URL: NgrokTunnel: \"https://8b76-61-114-134-7.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "NLTK loaded successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 77.88it/s]\n",
      "Device set to use cuda\n",
      "2025-04-30 02:35:42.586 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "Generated response in 1.21s\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "Generated response in 7.51s\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "  Stopping...\n",
      "🛑 終了中...\n",
      "🔒 ngrokトンネルを終了しました。\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# streamlit起動（8501番ポート）\n",
    "proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
    "\n",
    "# 起動をちょっと待つ（本来はポート確認がベター）\n",
    "time.sleep(5)\n",
    "\n",
    "# ngrokトンネル作成\n",
    "public_url = ngrok.connect(8501)\n",
    "print(f\"🔗 公開URL: {public_url}\")\n",
    "\n",
    "try:\n",
    "    proc.wait()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"🛑 終了中...\")\n",
    "    proc.terminate()\n",
    "    ngrok.kill()\n",
    "    print(\"🔒 ngrokトンネルを終了しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (02_streamlit_app)",
   "language": "python",
   "name": "streamlit_app_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
