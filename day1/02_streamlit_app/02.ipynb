{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f148279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95c4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/bin/python\n",
      "uv not found\n",
      "Python 3.12.10\n"
     ]
    }
   ],
   "source": [
    "!pip list\n",
    "!which python\n",
    "!which uv\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfe80c",
   "metadata": {},
   "source": [
    "ngrok ã¨ huggigface ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840a4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /home/tmiya/.config/ngrok/ngrok.yml\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `ai-enginnering-token` has been saved to /home/tmiya/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/tmiya/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `ai-enginnering-token`\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken $$NGROK_TOKEN\n",
    "!huggingface-cli login --token $$HUGGINGFACE_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397885f9",
   "metadata": {},
   "source": [
    "stramlit ã§ Huggingface ã®ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’æ‰±ã†ãŸã‚ã«ã€streamlit ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.streamlitï¼‰ã‚’ä½œæˆã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’æ ¼ç´ã—ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .streamlit/secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
    "import os\n",
    "\n",
    "import toml\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿\n",
    "os.makedirs(\".streamlit\", exist_ok=True)\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
    "secrets = {\"huggingface\": {\"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")}}\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
    "with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
    "    toml.dump(secrets, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17256fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 16.51it/s]\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from config import MODEL_NAME\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_NAME,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=device,\n",
    ")\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444e2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ã£ã¦çŸ¥ã£ã¦ã„ã‚‹ï¼Ÿï¼Ÿ\n",
      "\n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ã£ã¦çŸ¥ã£ã¦ã„ã‚‹ï¼Ÿï¼Ÿ\"\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=200,  # å‡ºåŠ›ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆæ–‡ç« ã®é•·ã•ï¼‰\n",
    "    temperature=0.7,  # ãƒ©ãƒ³ãƒ€ãƒ æ€§ï¼ˆå°ã•ã„ã»ã©å …ã„ã€1.0ãªã‚‰è‡ªç”±ï¼‰\n",
    "    top_p=0.95,  # nucleus samplingï¼ˆé€šå¸¸ã“ã‚Œã§ååˆ†ï¼‰\n",
    "    do_sample=True,  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã‹ï¼ˆTrueæ¨å¥¨ï¼‰\n",
    ")\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1f9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://172.22.108.179:8501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:8501: Operation not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— å…¬é–‹URL: NgrokTunnel: \"https://8b76-61-114-134-7.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "NLTK loaded successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 77.88it/s]\n",
      "Device set to use cuda\n",
      "2025-04-30 02:35:42.586 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tmiya/src/github.com/silbull/lecture-ai-engineering/day1/02_streamlit_app/.venv/lib/python3.12/site-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "Generated response in 1.21s\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "Generated response in 7.51s\n",
      "NLTK Punkt data checked/downloaded.\n",
      "Database 'chat_feedback.db' initialized successfully.\n",
      "  Stopping...\n",
      "ğŸ›‘ çµ‚äº†ä¸­...\n",
      "ğŸ”’ ngrokãƒˆãƒ³ãƒãƒ«ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# streamlitèµ·å‹•ï¼ˆ8501ç•ªãƒãƒ¼ãƒˆï¼‰\n",
    "proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
    "\n",
    "# èµ·å‹•ã‚’ã¡ã‚‡ã£ã¨å¾…ã¤ï¼ˆæœ¬æ¥ã¯ãƒãƒ¼ãƒˆç¢ºèªãŒãƒ™ã‚¿ãƒ¼ï¼‰\n",
    "time.sleep(5)\n",
    "\n",
    "# ngrokãƒˆãƒ³ãƒãƒ«ä½œæˆ\n",
    "public_url = ngrok.connect(8501)\n",
    "print(f\"ğŸ”— å…¬é–‹URL: {public_url}\")\n",
    "\n",
    "try:\n",
    "    proc.wait()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ğŸ›‘ çµ‚äº†ä¸­...\")\n",
    "    proc.terminate()\n",
    "    ngrok.kill()\n",
    "    print(\"ğŸ”’ ngrokãƒˆãƒ³ãƒãƒ«ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (02_streamlit_app)",
   "language": "python",
   "name": "streamlit_app_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
